{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b93b7e99-a9c0-4473-8a5c-340ad75fc364",
   "metadata": {},
   "source": [
    "# 모델 저장과 복원\n",
    "\n",
    "- 모델의 저장\n",
    "    - 긴 훈련 시간을 피할 수 있음\n",
    "    - 모델을 공유할 수 있음\n",
    "- 공유되는 내용\n",
    "    - 모델을 만드는 코드\n",
    "    - 모델의 훈련된 가중치 또는 파라미터\n",
    "    \n",
    "### 설정\n",
    "\n",
    "#### 설치와 임포트\n",
    "- pyyaml, h5py 라이브러리 설치 - HDF5 포맷으로 모델을 저장하기 위해서 필요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "437e302f-33af-4293-89fc-0b8e0c7b3a51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "print(tf.version.VERSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9638d334-9757-46ef-8041-dc7fc97de683",
   "metadata": {},
   "source": [
    "#### 데이터셋 받기\n",
    "- MNIST 데이터셋을 이용하여 모델을 만들고 저장\n",
    "- 모델의 실행 속도를 빠르게 하기 위해 처음 1,000개만 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9d03034-c95c-4948-9d7e-e1793299395d",
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "train_labels = train_labels[:1000]\n",
    "test_labels = test_labels[:1000]\n",
    "\n",
    "train_images = train_images[:1000].reshape(-1, 28 * 28) / 255.0\n",
    "test_images = test_images[:1000].reshape(-1, 28 * 28) / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b6811e-f043-4192-9a8c-27deed0f3540",
   "metadata": {},
   "source": [
    "#### 모델 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c2b13ea-c95c-4309-b649-a685a0a667e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 512)               401920    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 407,050\n",
      "Trainable params: 407,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-17 16:46:00.393796: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-02-17 16:46:00.395131: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "# 간단한 Sequential 모델을 정의합니다\n",
    "def create_model():\n",
    "  model = tf.keras.models.Sequential([\n",
    "    keras.layers.Dense(512, activation='relu', input_shape=(784,)),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.Dense(10)\n",
    "  ])\n",
    "\n",
    "  model.compile(optimizer='adam',\n",
    "                loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "  return model\n",
    "\n",
    "# 모델 객체를 만듭니다\n",
    "model = create_model()\n",
    "\n",
    "# 모델 구조를 출력합니다\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e54a0039-c49b-4132-9fad-48ec1078f87d",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "### 훈련하는 동안 체크포인트 저장하기\n",
    "- 훈련한 모델을 다시 훈련할 필요 없이 사용\n",
    "- 중단한 부분부터 다시 훈련을 시작\n",
    "- tf.keras.callbacks.ModelCheckpoint 콜백을 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "07c7b055-48dd-4063-a991-e5088bd5e89f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-17 16:49:51.105323: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-17 16:49:51.368642: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - ETA: 0s - loss: 1.1427 - accuracy: 0.6720\n",
      "Epoch 00001: saving model to training_1/cp.ckpt\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 1.1427 - accuracy: 0.6720 - val_loss: 0.7174 - val_accuracy: 0.7760\n",
      "Epoch 2/10\n",
      " 1/32 [..............................] - ETA: 0s - loss: 0.5445 - accuracy: 0.8750"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-17 16:49:52.117317: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/32 [====================>.........] - ETA: 0s - loss: 0.4335 - accuracy: 0.8859\n",
      "Epoch 00002: saving model to training_1/cp.ckpt\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.4143 - accuracy: 0.8890 - val_loss: 0.5200 - val_accuracy: 0.8290\n",
      "Epoch 3/10\n",
      "26/32 [=======================>......] - ETA: 0s - loss: 0.2802 - accuracy: 0.9279\n",
      "Epoch 00003: saving model to training_1/cp.ckpt\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.2809 - accuracy: 0.9280 - val_loss: 0.4814 - val_accuracy: 0.8420\n",
      "Epoch 4/10\n",
      "26/32 [=======================>......] - ETA: 0s - loss: 0.2033 - accuracy: 0.9531\n",
      "Epoch 00004: saving model to training_1/cp.ckpt\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.2021 - accuracy: 0.9530 - val_loss: 0.4407 - val_accuracy: 0.8560\n",
      "Epoch 5/10\n",
      "25/32 [======================>.......] - ETA: 0s - loss: 0.1396 - accuracy: 0.9725\n",
      "Epoch 00005: saving model to training_1/cp.ckpt\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1496 - accuracy: 0.9720 - val_loss: 0.4382 - val_accuracy: 0.8560\n",
      "Epoch 6/10\n",
      "26/32 [=======================>......] - ETA: 0s - loss: 0.1006 - accuracy: 0.9820\n",
      "Epoch 00006: saving model to training_1/cp.ckpt\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1018 - accuracy: 0.9810 - val_loss: 0.4350 - val_accuracy: 0.8610\n",
      "Epoch 7/10\n",
      "26/32 [=======================>......] - ETA: 0s - loss: 0.0784 - accuracy: 0.9868\n",
      "Epoch 00007: saving model to training_1/cp.ckpt\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0800 - accuracy: 0.9870 - val_loss: 0.4303 - val_accuracy: 0.8710\n",
      "Epoch 8/10\n",
      "26/32 [=======================>......] - ETA: 0s - loss: 0.0549 - accuracy: 0.9988\n",
      "Epoch 00008: saving model to training_1/cp.ckpt\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0572 - accuracy: 0.9950 - val_loss: 0.4145 - val_accuracy: 0.8650\n",
      "Epoch 9/10\n",
      "25/32 [======================>.......] - ETA: 0s - loss: 0.0513 - accuracy: 0.9962\n",
      "Epoch 00009: saving model to training_1/cp.ckpt\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0513 - accuracy: 0.9960 - val_loss: 0.4254 - val_accuracy: 0.8610\n",
      "Epoch 10/10\n",
      "23/32 [====================>.........] - ETA: 0s - loss: 0.0391 - accuracy: 1.0000\n",
      "Epoch 00010: saving model to training_1/cp.ckpt\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0360 - accuracy: 1.0000 - val_loss: 0.4128 - val_accuracy: 0.8710\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2a162ee50>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint_path = \"training_1/cp.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "# 모델의 가중치를 저장하는 콜백 만들기\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                 save_weights_only=True,\n",
    "                                                 verbose=1)\n",
    "\n",
    "# 새로운 콜백으로 모델 훈련하기\n",
    "model.fit(train_images, \n",
    "          train_labels,  \n",
    "          epochs=10,\n",
    "          validation_data=(test_images,test_labels),\n",
    "          callbacks=[cp_callback])  # 콜백을 훈련에 전달합니다\n",
    "\n",
    "# 옵티마이저의 상태를 저장하는 것과 관련되어 경고가 발생할 수 있습니다.\n",
    "# 이 경고는 (그리고 이 노트북의 다른 비슷한 경고는) 이전 사용 방식을 권장하지 않기 위함이며 무시해도 좋습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "85ec0e33-51a3-417b-8140-26fad8b79571",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cp.ckpt.data-00000-of-00001', 'checkpoint', 'cp.ckpt.index']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(checkpoint_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "929beb7d-6416-436c-95a4-d9fe875f90c9",
   "metadata": {},
   "source": [
    "- 두 모델이 동일한 아키텍처를 공유하기만 한다면 두 모델 간에 가중치를 공유할 수 있다. \n",
    "- 따라서 가중치 전용에서 모델을 복원할 때 원래 모델과 동일한 아키텍처로 모델을 만든 다음 가중치를 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61c11cdc-fcc6-4bc6-bb81-e297465553d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 - 0s - loss: 2.3495 - accuracy: 0.1340 - 176ms/epoch - 5ms/step\n",
      "훈련되지 않은 모델의 정확도: 13.40%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-17 16:52:26.824308: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "# 기본 모델 객체를 만듭니다\n",
    "model = create_model()\n",
    "\n",
    "# 모델을 평가합니다\n",
    "loss, acc = model.evaluate(test_images,  test_labels, verbose=2)\n",
    "print(\"훈련되지 않은 모델의 정확도: {:5.2f}%\".format(100*acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa90e3fe-9256-4e47-b586-80c487d82575",
   "metadata": {},
   "source": [
    "- 체크포인트에서 가중치 로드 후 다시 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "15c7fc18-3f78-4e44-bc35-642fbaec0104",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 - 0s - loss: 0.4128 - accuracy: 0.8710 - 101ms/epoch - 3ms/step\n",
      "복원된 모델의 정확도: 87.10%\n"
     ]
    }
   ],
   "source": [
    "# 가중치 로드\n",
    "model.load_weights(checkpoint_path)\n",
    "\n",
    "# 모델 재평가\n",
    "loss,acc = model.evaluate(test_images,  test_labels, verbose=2)\n",
    "print(\"복원된 모델의 정확도: {:5.2f}%\".format(100*acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc393d7-fd64-4b24-a5e2-aa44fb0cc381",
   "metadata": {},
   "source": [
    "#### 체크포인트 콜백 매개변수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "99c3268a-8182-48d5-9b6b-d4c1c3adaab5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-17 17:03:47.143254: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-02-17 17:03:47.447065: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00005: saving model to training_2/cp-0005.ckpt\n",
      "\n",
      "Epoch 00010: saving model to training_2/cp-0010.ckpt\n",
      "\n",
      "Epoch 00015: saving model to training_2/cp-0015.ckpt\n",
      "\n",
      "Epoch 00020: saving model to training_2/cp-0020.ckpt\n",
      "\n",
      "Epoch 00025: saving model to training_2/cp-0025.ckpt\n",
      "\n",
      "Epoch 00030: saving model to training_2/cp-0030.ckpt\n",
      "\n",
      "Epoch 00035: saving model to training_2/cp-0035.ckpt\n",
      "\n",
      "Epoch 00040: saving model to training_2/cp-0040.ckpt\n",
      "\n",
      "Epoch 00045: saving model to training_2/cp-0045.ckpt\n",
      "\n",
      "Epoch 00050: saving model to training_2/cp-0050.ckpt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x29d93a280>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 파일 이름에 에포크 번호를 포함시킵니다(`str.format` 포맷)\n",
    "checkpoint_path = \"training_2/cp-{epoch:04d}.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "# 다섯 번째 에포크마다 가중치를 저장하기 위한 콜백을 만듭니다\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_path, \n",
    "    verbose=1, \n",
    "    save_weights_only=True,\n",
    "    period=5)\n",
    "\n",
    "# 새로운 모델 객체를 만듭니다\n",
    "model = create_model()\n",
    "\n",
    "# `checkpoint_path` 포맷을 사용하는 가중치를 저장합니다\n",
    "model.save_weights(checkpoint_path.format(epoch=0))\n",
    "\n",
    "# 새로운 콜백을 사용하여 모델을 훈련합니다\n",
    "model.fit(train_images, \n",
    "          train_labels,\n",
    "          epochs=50, \n",
    "          callbacks=[cp_callback],\n",
    "          validation_data=(test_images,test_labels),\n",
    "          verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "249c2f7e-6a68-40ac-b905-e6efd27a4200",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cp-0005.ckpt.data-00000-of-00001',\n",
       " 'cp-0050.ckpt.index',\n",
       " 'cp-0005.ckpt.index',\n",
       " 'cp-0050.ckpt.data-00000-of-00001',\n",
       " 'checkpoint',\n",
       " 'cp-0020.ckpt.data-00000-of-00001',\n",
       " 'cp-0000.ckpt.index',\n",
       " 'cp-0030.ckpt.index',\n",
       " 'cp-0025.ckpt.data-00000-of-00001',\n",
       " 'cp-0000.ckpt.data-00000-of-00001',\n",
       " 'cp-0035.ckpt.index',\n",
       " 'cp-0010.ckpt.index',\n",
       " 'cp-0045.ckpt.index',\n",
       " 'cp-0045.ckpt.data-00000-of-00001',\n",
       " 'cp-0010.ckpt.data-00000-of-00001',\n",
       " 'cp-0035.ckpt.data-00000-of-00001',\n",
       " 'cp-0015.ckpt.index',\n",
       " 'cp-0040.ckpt.index',\n",
       " 'cp-0025.ckpt.index',\n",
       " 'cp-0030.ckpt.data-00000-of-00001',\n",
       " 'cp-0040.ckpt.data-00000-of-00001',\n",
       " 'cp-0015.ckpt.data-00000-of-00001',\n",
       " 'cp-0020.ckpt.index']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(checkpoint_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2b2ae355-01d7-4bc6-af12-1138e5c8b3e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'training_2/cp-0050.ckpt'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latest = tf.train.latest_checkpoint(checkpoint_dir)\n",
    "latest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ca10c3-4f8c-4b77-8fd7-ff325c16610f",
   "metadata": {},
   "source": [
    "> **참고: 기본 TensorFlow 형식은 가장 최근의 체크포인트 5개만 저장**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1c1696ee-9e97-4ede-a170-f1ed98cadc61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 - 0s - loss: 0.5124 - accuracy: 0.8720 - 170ms/epoch - 5ms/step\n",
      "복원된 모델의 정확도: 87.20%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-17 17:05:40.713189: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "# 새로운 모델 객체를 만듭니다\n",
    "model = create_model()\n",
    "\n",
    "# 이전에 저장한 가중치를 로드합니다\n",
    "model.load_weights(latest)\n",
    "\n",
    "# 모델을 재평가합니다\n",
    "loss, acc = model.evaluate(test_images,  test_labels, verbose=2)\n",
    "print(\"복원된 모델의 정확도: {:5.2f}%\".format(100*acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae7ac4d9-3a6e-4451-97a6-cbc0e930fa7a",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "### 이 파일들은 무엇인가요?\n",
    "\n",
    "- 위의 코드는 이진 형식의 훈련된 가중치만 포함하는 체크포인트 형식의 파일 모음에 가중치를 저장한다.\n",
    "- 체크 포인트에는 다음이 저장된다.\n",
    "    - 모델의 가중치를 포함하는 하나 이상의 샤드\n",
    "    - 어떤 가중치가 어떤 샤드에 저장되어 있는지 나타내는 인덱스 파일\n",
    "- 단일 머신에서 모델을 훈련하는 경우 접미사가 .data-00000-of-00001인 하나의 샤드를 갖게 된다.\n",
    "\n",
    "---\n",
    "### 수동으로 가중치 저장하기\n",
    "- `Model.save_weights` 메서드를 사용하여 수동으로 가중치를 저장\n",
    "- 기본적으로 tf.keras, 특히 save_weights는 .ckpt 확장자가 있는 TensorFlow 체크포인트 형식을 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0602e9a7-6b23-436c-b49f-a1d84cc9a84b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-18 09:50:04.928420: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 - 0s - loss: 0.5124 - accuracy: 0.8720 - 313ms/epoch - 10ms/step\n",
      "복원된 모델의 정확도: 87.20%\n"
     ]
    }
   ],
   "source": [
    "# 가중치를 저장합니다\n",
    "model.save_weights('./checkpoints/my_checkpoint')\n",
    "\n",
    "# 새로운 모델 객체를 만듭니다\n",
    "model = create_model()\n",
    "\n",
    "# 가중치를 복원합니다\n",
    "model.load_weights('./checkpoints/my_checkpoint')\n",
    "\n",
    "# 모델을 평가합니다\n",
    "loss,acc = model.evaluate(test_images,  test_labels, verbose=2)\n",
    "print(\"복원된 모델의 정확도: {:5.2f}%\".format(100*acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b75c40f5-adf3-4203-a9b2-1a7fcfa7a05f",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "### 전체 모델 저장하기\n",
    "\n",
    "- model.save 메서드를 호출하여 모델의 구조, 가중치, 훈련 설정을 하나의 파일/폴더에 저장\n",
    "- 원본 파이썬 코드가 없어도 사용 가능\n",
    "- 옵티마이저 상태가 복원되어 중지한 시점에서 훈련을 다시 시작할 수 있음\n",
    "- 두가지 다른 형식으로 저장 가능 (SavedModel, HDF5)\n",
    "- Tensorflow.js나 Tensorflolw Lite 등에서도 모델을 로드하여 사용 가능\n",
    "\n",
    "#### SavedModel 포맷\n",
    "- 형식으로 저장된 모델은 `tf.keras.models.load_model`을 사용하여 복원\n",
    "- Tensorflow Serving과 호환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7f7a2440-47a6-46bc-a29c-55b2dfd529d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      " 6/32 [====>.........................] - ETA: 0s - loss: 2.0630 - accuracy: 0.3229"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-18 09:57:29.318031: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 7ms/step - loss: 1.1610 - accuracy: 0.6730\n",
      "Epoch 2/5\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.4282 - accuracy: 0.8870\n",
      "Epoch 3/5\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.2902 - accuracy: 0.9320\n",
      "Epoch 4/5\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.2063 - accuracy: 0.9560\n",
      "Epoch 5/5\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.1629 - accuracy: 0.9650\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "INFO:tensorflow:Assets written to: saved_model/my_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-18 09:57:31.037605: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    }
   ],
   "source": [
    "# 새로운 모델 객체를 만들고 훈련합니다\n",
    "model = create_model()\n",
    "model.fit(train_images, train_labels, epochs=5)\n",
    "\n",
    "# SavedModel로 전체 모델을 저장합니다\n",
    "!mkdir -p saved_model\n",
    "model.save('saved_model/my_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e4fb144-e6cd-4888-aa04-0bae4f815878",
   "metadata": {},
   "source": [
    "- SavedModel 형식은 protobuf 바이너리와 TensorFlow 체크포인트를 포함하는 디렉토리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "937509f0-02bd-430f-b905-f6ba70bf9d68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mmy_model\u001b[m\u001b[m/\n",
      "\u001b[34massets\u001b[m\u001b[m/            keras_metadata.pb  saved_model.pb     \u001b[34mvariables\u001b[m\u001b[m/\n"
     ]
    }
   ],
   "source": [
    "# my_model 디렉토리\n",
    "%ls saved_model\n",
    "\n",
    "# assests 폴더, saved_model.pb, variables 폴더\n",
    "%ls saved_model/my_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c179227e-3973-40f6-b757-2253bd83ad06",
   "metadata": {},
   "source": [
    "- 저장된 모델로부터 새로운 모델 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6b94cc5a-01e7-4c89-916d-9855e5390d5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_10 (Dense)            (None, 512)               401920    \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 407,050\n",
      "Trainable params: 407,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "new_model = tf.keras.models.load_model('saved_model/my_model')\n",
    "\n",
    "# 모델 구조를 확인합니다\n",
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "84c4b796-e55c-4a66-b7f4-313d60cbad40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 - 0s - loss: 0.4517 - accuracy: 0.8550 - 217ms/epoch - 7ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-18 10:02:53.156661: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "복원된 모델의 정확도: 85.50%\n",
      "(1000, 10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-18 10:02:53.440760: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "# 복원된 모델을 평가합니다\n",
    "loss, acc = new_model.evaluate(test_images,  test_labels, verbose=2)\n",
    "print('복원된 모델의 정확도: {:5.2f}%'.format(100*acc))\n",
    "\n",
    "print(new_model.predict(test_images).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c8b61d-5090-4ccc-9843-b08d3679b695",
   "metadata": {},
   "source": [
    "#### HDF5 파일로 저장하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "59754a54-32e9-4036-b62e-2a48627bbb0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      " 7/32 [=====>........................] - ETA: 0s - loss: 1.9692 - accuracy: 0.3616"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-18 10:03:56.196978: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 6ms/step - loss: 1.1620 - accuracy: 0.6560\n",
      "Epoch 2/5\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.4278 - accuracy: 0.8780\n",
      "Epoch 3/5\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.2873 - accuracy: 0.9170\n",
      "Epoch 4/5\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.2016 - accuracy: 0.9530\n",
      "Epoch 5/5\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.1544 - accuracy: 0.9680\n"
     ]
    }
   ],
   "source": [
    "# 새로운 모델 객체를 만들고 훈련합니다\n",
    "model = create_model()\n",
    "model.fit(train_images, train_labels, epochs=5)\n",
    "\n",
    "# 전체 모델을 HDF5 파일로 저장합니다\n",
    "# '.h5' 확장자는 이 모델이 HDF5로 저장되었다는 것을 나타냅니다\n",
    "model.save('my_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32677c74-ee14-4eae-bea1-32cb4bf9e419",
   "metadata": {},
   "source": [
    "- .h5 파일로부터 모델을 다시 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e0676957-eab0-4ba4-97ab-16c82377e1d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_12 (Dense)            (None, 512)               401920    \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 407,050\n",
      "Trainable params: 407,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 가중치와 옵티마이저를 포함하여 정확히 동일한 모델을 다시 생성합니다\n",
    "new_model = tf.keras.models.load_model('my_model.h5')\n",
    "\n",
    "# 모델 구조를 출력합니다\n",
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c00df137-8476-43b2-8296-3be846644cfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 - 0s - loss: 0.4469 - accuracy: 0.8560 - 172ms/epoch - 5ms/step\n",
      "복원된 모델의 정확도: 85.60%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-18 10:05:44.776935: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "loss, acc = new_model.evaluate(test_images,  test_labels, verbose=2)\n",
    "print('복원된 모델의 정확도: {:5.2f}%'.format(100*acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecc5bfe5-47fb-41d7-8295-31a62daf609d",
   "metadata": {},
   "source": [
    "- 저장되는 내용\n",
    "    - 가중치 값\n",
    "    - 모델 구조\n",
    "    - 모델의 훈련 구성(.compile() 메서드에 전달하는 내용)\n",
    "    - 존재하는 옵티마이저와 그 상태(훈련을 중단한 곳에서 다시 시작할 수 있게 해줌)\n",
    "    \n",
    "> 체크포인트가 호환되지 않기 때문에 케라스는 v1.x 옵티마이저(tf.compat.v1.train)를 저장할 수 없다.\n",
    "\n",
    "#### 사용자 정의 객체\n",
    "- HDF5와 SavedModel의 주요 차이점\n",
    "    - HDF5는 객체 구성을 사용하여 모델 아키텍처를 저장\n",
    "    - SavedModel은 실행 그래프를 저장\n",
    "- 따라서 SavedModel은 원본 코드 없이도 서브클래싱된 모델 및 사용자 지정 레이어와 같은 사용자 지정 객체를 저장할 수 있다.\n",
    "- 사용자 정의 객체를 HDF5로 저장하려면 다음 과정을 따라야 한다.\n",
    "    1. 이 객체에 get_config 메서드를 정의하고 선택적으로 from_config 클래스 메서드를 정의한다.\n",
    "        - get_config(self)는 객체를 다시 생성하기 위해 필요한 JSON 직렬화된 매개변수 딕셔너리를 반환한다.\n",
    "        - from_config(cls, config)는 get_config에서 반환된 설정을 사용해 새로운 객체를 만든다. 기본적으로 이 함수는 이 설정을 초기화 메서드의 매개변수로 사용한다(return cls(**config)).\n",
    "    2. 모델을 로드할 때 이 객체를 custom_objects 매개변수로 전달한다. 문자열 클래스 이름과 파이썬 클래스를 매핑한 딕서너리를 매개변수로 제공해야 한다. 예를 들면 tf.keras.models.load_model(path, custom_objects={'CustomLayer': CustomLayer})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e9bee70-e260-4268-898c-779e9b14451b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
