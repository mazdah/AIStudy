{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c13134a-74ff-4e0a-8e19-7ddfa9c1c7d4",
   "metadata": {},
   "source": [
    "# 1.1 머신러닝이란?\n",
    "\n",
    "> 명시적인 프로그래밍 없이 컴퓨터가 학습하는 능력을 갖추게 하는 연구분야 - 아서 새뮤얼\n",
    "\n",
    "> 어떤 작업 T에 대한 컴퓨터 프로그램의 성능을 P로 측정했을 대 경험 E로 인해 성능이 향상됐다면  \n",
    "> 이 컴퓨터 프로그램은 작업 T와 성능 측정 P에 대해 경험 E로 학습한 것이다. - 톰 미첼"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f1d2e2-8ce3-4738-ac2b-9cbc372a3150",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f1e669-c3c4-4b67-bba0-a7a365caa84b",
   "metadata": {},
   "source": [
    "# 1.2 왜 머신러닝을 사용하는가?\n",
    "\n",
    "- 기존 솔루션으로는 많은 수동 조정과 규칙이 필요한 문제 해결\n",
    "- 전통적인 방식으로는 너무 복잡하거나 알려진 알고리즘이 없는 문제 해결\n",
    "- 유동적인 환경\n",
    "- 복잡한 문제와 대량의 데이터에서 통찰을 얻기 위해"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dbc7c07-a7ea-4f20-9753-b19d96e199c6",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db4fe68a-1156-4eb4-87ef-7596a6a9229c",
   "metadata": {},
   "source": [
    "# 1.3 애플리케이션 사례\n",
    "\n",
    "- 이미지 분석, 텍스트 분석, 값 예측, 음성 분석, 이상치 탐지, 데이터 시각화, 상품 추천, 지능형 게임 봇 등"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "299c57b4-2b91-455b-b215-82befc4402cc",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b9c4c32-4ed6-4892-8455-4d60e12a8d79",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1.4 머신러닝 시스템의 종류\n",
    "\n",
    "- 분류 기준\n",
    "    - 사람의 감독하에 훈련하는 것인지 그렇지 않은 것인지\n",
    "    - 실시간으로 점진적인 학습을 하는지 아닌지\n",
    "    - 단순하게 알고 있는 데이터 포인트와 새 데이터 포인트를 비교하는 것인지 훈련 데이터셋에서 패턴을 발견하여 예측 모델을 만드는지\n",
    "    \n",
    "### 1.4.1 지도 학습과 비지도 학습\n",
    "\n",
    "- **지도 학습**<sup>supervised learning</sup>\n",
    "    - 알고리즘에 주입하는 훈련 데이터에 **레이블**<sup>label</sup>이라는 정답이 포함된다.\n",
    "    - 분류와 회귀가 전형적인 지도학습\n",
    "    - 중요한 지도 학습 알고리즘\n",
    "        - k-최근접 이웃<sup>k-nearest neighbors</sup>\n",
    "        - 선형 회귀<sup>linear regression</sup>\n",
    "        - 로지스틱 회귀<sup>logistic regression</sup>\n",
    "        - 서포트 벡터 머신<sup>support vector machine</sup>(SVM)\n",
    "        - 결정 트리<sup>decision tree</sup>와 랜덤 포레스트<sup>random forest</sup>\n",
    "        - 신경망<sup>neural network</sup>\n",
    "- **비지도 학습**<sup>unsupervised leaning</sup>\n",
    "    - 훈련 데이터에 레이블이 없다(시스템이 아무런 도움 없이 스스로 학습).\n",
    "    - 중요한 비지도 학습 알고리즘\n",
    "        - 군집<sup>clustering</sup>\n",
    "            - k-평균<sup>k-means</sup>\n",
    "            - DBSCAN\n",
    "            - 계층 군집 분석<sup>hirerachical cluster analysis</sup>(HCA)\n",
    "            - 이상치 탐지<sup>outlier detection</sup>와 특이치 탐지<sup>novelty detection</sup>\n",
    "            - 원-클래스<sup>one-class SVM</sup>\n",
    "            - 아이솔레이션 포레스트<sup>isolation forest</sup>\n",
    "        - 시각화<sup>visualization</sup>와 차원 축소<sup>dimensionality reduction</sup>\n",
    "            - 주성분 분석<sup>principal component analysis</sup>(PCA)\n",
    "            - 커널<sup>kernel</sup>PCA\n",
    "            - 지역적 선형 임베딩<sup>locality-linearembedding</sup>(LLE)\n",
    "            - t-SNE<sup>t-distributed stochastic neighbor embedding</sup>\n",
    "        - 연관 규칙 학습<sup>association rule</sup>\n",
    "            - 어프라이어리<sup>Apriori</sup>\n",
    "            - 이클렛<sup>Eclat</sup>\n",
    "- 준지도 학습<sup>semisupervised leaning</sup>\n",
    "    - 일부만 레이블이 있는 데이터를 다룬다.\n",
    "    - 대부분의 준지도 학습 알고리즘은 지도 학습과 비지도 학습의 조합으로 이루어짐\n",
    "- 강화 학습<sup>reinforcement learning</sup>\n",
    "    - **에이전트**가 환경을 관할하여 행동을 실행하고 그 결과로 **보상**<sup>reward</sup>을 받으며 시간이 지날수록 보상을 얻기 위해 **정책**<sup>policy</sup>이라 부르는 최상위 전략을 스스로 학습하는 방법\n",
    "    \n",
    "### 1.4.2 배치 학습과 온라인 학습\n",
    "\n",
    "- 배치 학습<sup>batch learning</sup>\n",
    "    - 가용한 데이터를 모두 사용하여 훈련\n",
    "    - 시간과 자원을 많이 소모하여 오프라인에서 수행\n",
    "    - 학습한 것을 단지 적용만 함. 오프라인 학습<sup>offline learning</sup>\n",
    "- 온라인 학습<sup>online learning</sup>\n",
    "    - 데이터를 순차적으로 혹은 미니배치<sup>mini-batch</sup>라 부르는 작은 묶음 단위로 사용하여 시스템 훈련\n",
    "    - 학습 단계가 빠르고 비용이 적게 들어 데이터가 도착하는 즉시 학습 가능\n",
    "    - 연속적으로 데이터를 받고 빠른 변화에 스스로 적응해야 하는 시스템에 적합\n",
    "    - 컴퓨팅 자원이 제한된 상황에도 좋음\n",
    "    - 컴퓨터 한 대의 메인 메모리에 들어갈 수 없는 매우 큰 데이터셋을 학습(외부 메모리 학습, 보통 오프라인으로 실행된다. 점진적 학습)\n",
    "    - 변화하는 데이터에 얼마나 빠르게 적응할 것인지를 결정하는 **학습률**<sup>learning rate</sup> 파라미터가 매우 중요\n",
    "    - 나쁜 데이터가 주입되는 경우 성능이 점진적으로 감소\n",
    "    \n",
    "### 1.4.3 사례 기반 학습과 모델 기반 학습\n",
    "\n",
    "- 어떻게 일반화<sup>generalize</sup> 되는가에 따른 분류\n",
    "- 학습의 진짜 목표는 새로운 샘플에 잘 작동하는 모델 생성\n",
    "- 사례 기반 학습<sup>instance-based learning</sup>\n",
    "    - 단순히 사례를 기억하여 처리\n",
    "    - 기억하고 있는 훈련에 사용한 샘플과 새로운 데이터를 유사도 측정을 이용해 비교\n",
    "- 모델 기반 학습<sup>model-based learning</sup>\n",
    "    - 모델을 만들어 예측에 사용하는 것\n",
    "    - 모델의 성능을 측정하는 효용 함수 또는 비용 함수 필요\n",
    "    - 과정\n",
    "        - 데이터 분석\n",
    "        - 모델 선택\n",
    "        - 훈련 데이터로 모델 훈련\n",
    "        - 새로운 데이터에 모델 적용, 예측"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a03d68-e938-45c7-8f41-01d172bef024",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2ee1552-668b-4807-86d1-b9918433b847",
   "metadata": {},
   "source": [
    "# 1.5 머신러닝의 주요 도전 과제\n",
    "\n",
    "- 문제가 될 수 있는 두 가지는 '나쁜 알고리즘'과 '나쁜 데이터'\n",
    "\n",
    "### 1.5.1 충분하지 않은 양의 훈련 데이터\n",
    "\n",
    "- 머신러닝이 잘 동작하기 위해서는 데이터가 많아야 한다.\n",
    "- 현실적인 한계로 충분한 데이터를 확보하는 것이 언제나 쉽고 저렴하지는 않다.\n",
    "\n",
    "### 1.5.2 대표성 없는 훈련 데이터\n",
    "\n",
    "- 예측하고자 하는 새로운 사례를 훈련 데이터가 잘 대표해야 한다.\n",
    "- 샘플링 잡음이나 샘플링 편향을 피해야 한다.\n",
    "\n",
    "### 1.5.3 낮은 품질의 데이터\n",
    "\n",
    "- 에러, 이상치, 잡음이 많은 데이터는 부적절\n",
    "- 데이터 정제에 많은 시간을 할애할 필요가 있다.\n",
    "\n",
    "### 1.5.4 관련 없는 특성\n",
    "\n",
    "- 특성 공학<sup>feature engineering</sup>: 데이터로부터 훈련에 사용할 좋은 특성을 찾는 것\n",
    "    - 특성 선택: 가장 유용한 특성 선택한다.\n",
    "    - 특성 추출: 특성을 결합하여 더 유용한 특성을 만든다.\n",
    "    - 새로운 데이터를 수집해 새 특성을 만든다.\n",
    "    \n",
    "### 1.5.5 훈련 데이터 과대적합\n",
    "\n",
    "- **과대적합**<sup>overfitting</sup>: 모델이 훈련 데이터에 너무 잘 맞지만 일반성이 떨어지는 경우\n",
    "- 훈련 데이터에 있는 잡음의 양에 비해 모델이 너무 복잡한 경우 발생\n",
    "- 규제<sup>regularization</sup>를 이용하여 회피\n",
    "- 규제의 양은 하이퍼파라미터로 결정\n",
    "\n",
    "### 1.5.6 훈련 데이터 과소적합\n",
    "\n",
    "- **과소적합**<sup>underfitting</sup>: 모델이 너무 단순하여 데이터의 내재된 구조를 학습하지 못하는 경우\n",
    "- 해결 방법\n",
    "    - 모델 파라미터가 더 많은 강력한 모델 선택\n",
    "    - 학습 알고리즘에 더 좋은 특성 제공\n",
    "    - 모델의 제약을 줄임\n",
    "    \n",
    "### 1.5.7 한걸음 물러서서\n",
    "\n",
    "- 내용 정리"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "095c065e-da08-4d94-9aef-604b4f6e4903",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab83621c-ba81-47fa-ab7d-7dffcea58484",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# 1.6 테스트와 검증\n",
    "\n",
    "- 훈련 데이터를 훈련 세트와 테스트 세트로 분리\n",
    "- 일반화 오차(외부 샘플 오차): 새로운 샘플에 대한 오류 비율. 테스트 세트에서 모델을 평하하여 추정값을 얻음\n",
    "\n",
    "### 1.6.1 하이퍼파라미터 튜닝과 모델 선택\n",
    "\n",
    "- 모델 평가는 단지 테스트 세트를 사용하여 측정\n",
    "- 홀드아웃 검즘: 훈련 세트 일부(**검증 세트**)를 떼어내어 여러 후보 모델을 평가하고 가장 좋은 하나를 선택\n",
    "- 작은 검증 세트를 여러개 만들어 반복적으로 교차 검증을 수행해야 한다.\n",
    "- 데이터 불일치\n",
    "    - 검증 세트와 테스트 세트에 대표 데이터가 배타적으로 포함되어야 한다.\n",
    "    - 데이터 불일치 판단 과정\n",
    "        - 훈련 데이터의 일부를 떼어내 훈련-개발 세트를 만든다.\n",
    "        - 모델을 훈련 세트에서 훈련한 후 훈련-개발 세트에서 평가한다.\n",
    "        - 모델이 잘 작동하면 과대적합이 아니라고 판단. 잘 작동하지 않는다면 과대적합\n",
    "        - 과대적합이 아닌 경우 검증 세트에서 나쁜 성능을 내는 경우 데이터 불일치로 판단."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "652be6c0-79f9-416a-8c62-faf8edcaf97e",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ef419d-f1d5-42a1-81e7-c613ccedf4ea",
   "metadata": {},
   "source": [
    "# 1.7 연습 문제\n",
    "\n",
    "1. 머신러닝을 어떻게 정의할 수 있나요?\n",
    "\n",
    "2. 머신러닝이 도움을 줄 수 있는 문제 유형 네 가지를 말해보세요.\n",
    "\n",
    "3. 레이블된 훈련 세트란 무엇인가요?\n",
    "\n",
    "4. 가장 널리 사용되는 지도 학습 작업 두 가지는 무엇인가요?\n",
    "\n",
    "5. 보편적인 비지도 학습 작업 네 가지는 무엇인가요?\n",
    "\n",
    "6. 사전 정보가 없는 여러 지형에서 로봇을 걸어가게 하려면 어떤 종류의 머신러닝 알고리즘을 사용할 수 있나요?\n",
    "\n",
    "7. 고객을 여러 그룹으로 분할하려면 어떤 알고리즘을 사용해야 하나요?\n",
    "\n",
    "8. 스팸 감지의 문제는 지도 학습과 비지도 학습 중 어떤 문제로 볼 수 있나요?\n",
    "\n",
    "9. 온라인 학습 시스템이 무엇인가요?\n",
    "\n",
    "10. 외부 메모리 학습이 무엇인가요?\n",
    "\n",
    "11. 예측을 하기 위해 유사도 측정에 의존하는 학습 알고리즘은 무엇인가요?\n",
    "\n",
    "12. 모델 파라미터와 학습 알고리즘의 하이퍼파라미터 사이에는 어떤 차익 있나요?\n",
    "\n",
    "13. 모델 기반 알고리즘이 찾는 것은 무엇인가요? 성공을 위해 이 알고리즘이 사용하는 가장 일반적인 전략은 무엇인가요? 예측은 어떻게 만드나요?\n",
    "\n",
    "14. 머신러닝의 주요 도전 과제는 무엇인가요?\n",
    "\n",
    "15. 모델이 훈련 데이터에서의 성능은 좋지만 새로운 샘플에서의 일반화 성능이 나쁘다면 어던 문제가 있는 건가요? 가능한 해결책 세 가지는 무엇인가요?\n",
    "\n",
    "16. 테스트 세트가 무엇이고 왜 사용해야 하나요?\n",
    "\n",
    "17. 검증 세트의 목적은 무엇인가요?\n",
    "\n",
    "18. 훈련-개발 세트가 무엇인가요? 언제 필요하고 어떻게 사용해야 하나요?\n",
    "\n",
    "19. 테스트 세트를 사용해 하이퍼파라미터를 튜닝하면 어던 문제가 생기나요?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7664e66c-4948-4515-aa03-8d76c9517b14",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
