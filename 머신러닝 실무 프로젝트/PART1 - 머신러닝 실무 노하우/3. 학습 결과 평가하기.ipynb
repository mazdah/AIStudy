{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fee9ea7e-ef4f-4535-87d9-2045006f5e94",
   "metadata": {},
   "source": [
    "# 3.1 분류 결과에 대한 평가 행렬\n",
    "\n",
    "- 스팸 분류 예에서의 지표 \n",
    "    - 정확도\n",
    "    - 정밀도\n",
    "    - 재현율\n",
    "    - F-점수\n",
    "- 학습할 개념\n",
    "    - 혼동행렬\n",
    "    - 마이크로 평균, 매크로 평균\n",
    "\n",
    "### 3.1.1 그냥 정확도를 사용하면 될까?\n",
    "\n",
    "- 분류에서는 결과가 얼마나 바르게 나위었는가를 기준으로 분류기의 성능 평가\n",
    "- 정확도의 정의\n",
    "> $ 정확도 = \\frac{정답과 일치한 수}{전체 데이터 수}$\n",
    "- 분류 문제는 일반적으로 무작위로 선택한 결과를 최저 성능으로 삼음\n",
    "- 대상 클래스의 분포 자체가 치우친 경우 정확도만으로는 의미가 없음\n",
    "\n",
    "### 3.1.2 데이터 분포가 치우친 경우를 위한 지표 - 정밀도와 재현율\n",
    "\n",
    "- **정밀도**<sup>precision</sup>: 출력 결과가 정담을 얼마나 맞혔는지에 대한 지표\n",
    "> $ 정밀도 = \\frac{진짜 정답의 수}{정답으로 출력한 수} = \\frac{TP}{TP + FP}$\n",
    "- **재현율**<sup>recall</sup>: 출력 결과가 실제 정답 중 얼마나 맞혔는지에 대한 지표\n",
    "> $ 재현율 = \\frac{정답으로 출력한 수}{전체 데이터에 포함된 진짜 정답 수} = \\frac{TP}{TP + FN}$\n",
    "- 정밀도와 재현율은 상충관계\n",
    "\n",
    "### 3.1.3 균형 잡힌 성능을 평가하는 F-점수\n",
    "\n",
    "- **F-점수**<sup>F-measure</sup>: 정밀도와 재현율의 상충관계를 평가에 반영하여 실제 분류기를 비교하는 데 사용되는 지표\n",
    "- 정밀도와 재현율의 조화평균\n",
    "> $ F-점수 = \\frac{2}{\\frac{1}{정밀도}+\\frac{1}{재현율}}$\n",
    "- 재현율과 정밀도가 균형을 이룰 때 F-점수가 높아진다.\n",
    "\n",
    "### 3.1.4 혼동행렬 따라잡기\n",
    "\n",
    "- 혼동행렬<sup>confusion matrix</sup>: \n",
    "![혼동행렬](./images/confmatrix.png)\n",
    "\n",
    "- 사이킷런의 혿동행렬 계산 함수 confusion_matrix 사용 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d27d07d-dabc-4f4a-8990-836c1fbae1e6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m confusion_matrix\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# 데이터를 훈련 데이터와 테스트 데이터로 분할\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m data_train, data_test, label_train, label_test \u001b[38;5;241m=\u001b[39m train_test_split(\u001b[43mdata\u001b[49m, label)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# 분류기로 예측. 선형 SVM 사용 예\u001b[39;00m\n\u001b[1;32m      8\u001b[0m classifier \u001b[38;5;241m=\u001b[39m svm\u001b[38;5;241m.\u001b[39mSVC(kernel\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlinear\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# 데이터를 훈련 데이터와 테스트 데이터로 분할\n",
    "data_train, data_test, label_train, label_test = train_test_split(data, label)\n",
    "\n",
    "# 분류기로 예측. 선형 SVM 사용 예\n",
    "classifier = svm.SVC(kernel='linear')\n",
    "label_pred = classifier.fit(data_train, label_train).predict(data_test)\n",
    "\n",
    "# 혼동행렬 계산\n",
    "cm = confusion_matrix(label_test, label_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb409f51-c718-4125-8981-c4214bd935b3",
   "metadata": {},
   "source": [
    "### 3.1.5 다중 클래스 분류의 평균 구하기 - 마이크로 평균과 매크로 평균\n",
    "\n",
    "- 마이크로 평균<sup>micro-average</sup>: 모든 클래스의 결과를 합쳐 전체를 평가.\n",
    "> $ 정밀도_{마이크로 평균} = \\frac{TP_1 + TP_2 + TP_3}{TP_1 + TP_2 + TP_3 + FP_1 + FP_2 + FP_3}$ (3 개의 클래스 분류 시)\n",
    "- 매크로 평균<sup>macro-average</sup>: 클래스별 정밀도를 계산한 다음 클래스 단위로 이 정밀도의 평균을 구해 계산. 클래스를 나누지 않은 전체 성능의 양상을 알기에 적합. 클래스마다 데이터의 수에 차이가 나는 경우 사용\n",
    "> $ 정밀도_{매크로 평균} = \\frac{정밀도_1 + 정밀도_2 + 정밀도_3}{3}$  (3 개의 클래스 분류 시)\n",
    "\n",
    "### 3.1.6 분류 모델 비교하기\n",
    "\n",
    "- 모델들의 성능 비교 시에는 F-점수를 많이 사용.\n",
    "- F-점수 외에도 ROC 곡선<sup>receiver operating characteristics curve</sup>나 이 곡선으로부터 계산하는 AUC<sup>area ubnder the curve</sup> 등의 지표가 있다.\n",
    "- 학습 모델의 성능이 높은 것과 비지니스 목적을 달성하는 것은 별개의 문제!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98742b4b-b58b-4ffc-9fc1-fd2a147b5ed2",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ad76ffa-3140-471a-9c8f-02fd8853fcb2",
   "metadata": {},
   "source": [
    "# 3.2 회귀 모델 평가하기\n",
    "\n",
    "- 평균제곱근오차와 결정 계수\n",
    "\n",
    "### 3.2.1 평균제곱근오차<sup>root mean squared error</sup>(RMSE) \n",
    "\n",
    "- 평균제곱근오차: 예측값 배열과 실젯값 배열의 각 요소의 차를 제곱하여 합하고 전체 배열 수로 나눈 뒤 제곱근을 취한 값\n",
    "> $ RMSE = \\sqrt{\\frac{\\sum_i{(예측값_i - 실젯값_i)^2}}{N}} $\n",
    "- 평균제곱근오차 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db030391-4c14-4b60-a594-05d8a89ed051",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'predicts' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmath\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m sqrt\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28msum\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m predict, actual \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[43mpredicts\u001b[49m, actual):\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28msum\u001b[39m \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (predict \u001b[38;5;241m-\u001b[39m actual) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[1;32m      8\u001b[0m sqrt(\u001b[38;5;28msum\u001b[39m \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(predicts))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'predicts' is not defined"
     ]
    }
   ],
   "source": [
    "from math import sqrt\n",
    "\n",
    "sum = 0\n",
    "\n",
    "for predict, actual in zip(predicts, actual):\n",
    "    sum += (predict - actual) ** 2\n",
    "    \n",
    "sqrt(sum / len(predicts))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a54ec4f7-ef58-48e9-8def-466002159b89",
   "metadata": {},
   "source": [
    "- 사이킷런에는 mean_squared_error 함수(평균제곱근오차가 아닌 평균제곱오차 함수임!)로 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36a7dfb5-4017-4efc-b19f-2687df514cc4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_actual' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mean_squared_error\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmath\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m sqrt\n\u001b[0;32m----> 4\u001b[0m rms \u001b[38;5;241m=\u001b[39m sqrt(mean_squared_error(\u001b[43my_actual\u001b[49m, y_predict))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'y_actual' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "\n",
    "rms = sqrt(mean_squared_error(y_actual, y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b9141f-28f0-4f1f-bf85-354d47258ecc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
