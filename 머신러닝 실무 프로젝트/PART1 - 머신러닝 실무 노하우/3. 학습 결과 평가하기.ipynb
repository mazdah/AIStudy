{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fee9ea7e-ef4f-4535-87d9-2045006f5e94",
   "metadata": {},
   "source": [
    "# 3.1 분류 결과에 대한 평가 행렬\n",
    "\n",
    "- 스팸 분류 예에서의 지표 \n",
    "    - 정확도\n",
    "    - 정밀도\n",
    "    - 재현율\n",
    "    - F-점수\n",
    "- 학습할 개념\n",
    "    - 혼동행렬\n",
    "    - 마이크로 평균, 매크로 평균\n",
    "\n",
    "### 3.1.1 그냥 정확도를 사용하면 될까?\n",
    "\n",
    "- 분류에서는 결과가 얼마나 바르게 나위었는가를 기준으로 분류기의 성능 평가\n",
    "- 정확도의 정의\n",
    "> $ 정확도 = \\frac{정답과 일치한 수}{전체 데이터 수}$\n",
    "- 분류 문제는 일반적으로 무작위로 선택한 결과를 최저 성능으로 삼음\n",
    "- 대상 클래스의 분포 자체가 치우친 경우 정확도만으로는 의미가 없음\n",
    "\n",
    "### 3.1.2 데이터 분포가 치우친 경우를 위한 지표 - 정밀도와 재현율\n",
    "\n",
    "- **정밀도**<sup>precision</sup>: 출력 결과가 정담을 얼마나 맞혔는지에 대한 지표\n",
    "> $ 정밀도 = \\frac{진짜 정답의 수}{정답으로 출력한 수} = \\frac{TP}{TP + FP}$\n",
    "- **재현율**<sup>recall</sup>: 출력 결과가 실제 정답 중 얼마나 맞혔는지에 대한 지표\n",
    "> $ 재현율 = \\frac{정답으로 출력한 수}{전체 데이터에 포함된 진짜 정답 수} = \\frac{TP}{TP + FN}$\n",
    "- 정밀도와 재현율은 상충관계\n",
    "\n",
    "### 3.1.3 균형 잡힌 성능을 평가하는 F-점수\n",
    "\n",
    "- **F-점수**<sup>F-measure</sup>: 정밀도와 재현율의 상충관계를 평가에 반영하여 실제 분류기를 비교하는 데 사용되는 지표\n",
    "- 정밀도와 재현율의 조화평균\n",
    "> $ F-점수 = \\frac{2}{\\frac{1}{정밀도}+\\frac{1}{재현율}}$\n",
    "- 재현율과 정밀도가 균형을 이룰 때 F-점수가 높아진다.\n",
    "\n",
    "### 3.1.4 혼동행렬 따라잡기\n",
    "\n",
    "- 혼동행렬<sup>confusion matrix</sup>: \n",
    "![혼동행렬](./images/confmatrix.png)\n",
    "\n",
    "- 사이킷런의 혿동행렬 계산 함수 confusion_matrix 사용 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d27d07d-dabc-4f4a-8990-836c1fbae1e6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m confusion_matrix\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# 데이터를 훈련 데이터와 테스트 데이터로 분할\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m data_train, data_test, label_train, label_test \u001b[38;5;241m=\u001b[39m train_test_split(\u001b[43mdata\u001b[49m, label)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# 분류기로 예측. 선형 SVM 사용 예\u001b[39;00m\n\u001b[1;32m      8\u001b[0m classifier \u001b[38;5;241m=\u001b[39m svm\u001b[38;5;241m.\u001b[39mSVC(kernel\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlinear\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# 데이터를 훈련 데이터와 테스트 데이터로 분할\n",
    "data_train, data_test, label_train, label_test = train_test_split(data, label)\n",
    "\n",
    "# 분류기로 예측. 선형 SVM 사용 예\n",
    "classifier = svm.SVC(kernel='linear')\n",
    "label_pred = classifier.fit(data_train, label_train).predict(data_test)\n",
    "\n",
    "# 혼동행렬 계산\n",
    "cm = confusion_matrix(label_test, label_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb409f51-c718-4125-8981-c4214bd935b3",
   "metadata": {},
   "source": [
    "### 3.1.5 다중 클래스 분류의 평균 구하기 - 마이크로 평균과 매크로 평균\n",
    "\n",
    "- 마이크로 평균<sup>micro-average</sup>: 모든 클래스의 결과를 합쳐 전체를 평가.\n",
    "> $ 정밀도_{마이크로 평균} = \\frac{TP_1 + TP_2 + TP_3}{TP_1 + TP_2 + TP_3 + FP_1 + FP_2 + FP_3}$ (3 개의 클래스 분류 시)\n",
    "- 매크로 평균<sup>macro-average</sup>: 클래스별 정밀도를 계산한 다음 클래스 단위로 이 정밀도의 평균을 구해 계산. 클래스를 나누지 않은 전체 성능의 양상을 알기에 적합. 클래스마다 데이터의 수에 차이가 나는 경우 사용\n",
    "> $ 정밀도_{매크로 평균} = \\frac{정밀도_1 + 정밀도_2 + 정밀도_3}{3}$  (3 개의 클래스 분류 시)\n",
    "\n",
    "### 3.1.6 분류 모델 비교하기\n",
    "\n",
    "- 모델들의 성능 비교 시에는 F-점수를 많이 사용.\n",
    "- F-점수 외에도 ROC 곡선<sup>receiver operating characteristics curve</sup>나 이 곡선으로부터 계산하는 AUC<sup>area ubnder the curve</sup> 등의 지표가 있다.\n",
    "- 학습 모델의 성능이 높은 것과 비지니스 목적을 달성하는 것은 별개의 문제!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98742b4b-b58b-4ffc-9fc1-fd2a147b5ed2",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ad76ffa-3140-471a-9c8f-02fd8853fcb2",
   "metadata": {},
   "source": [
    "# 3.2 회귀 모델 평가하기\n",
    "\n",
    "- 평균제곱근오차와 결정 계수\n",
    "\n",
    "### 3.2.1 평균제곱근오차<sup>root mean squared error</sup>(RMSE) \n",
    "\n",
    "- 평균제곱근오차: 예측값 배열과 실젯값 배열의 각 요소의 차를 제곱하여 합하고 전체 배열 수로 나눈 뒤 제곱근을 취한 값\n",
    "> $ RMSE = \\sqrt{\\frac{\\sum_i{(예측값_i - 실젯값_i)^2}}{N}} $\n",
    "- 평균제곱근오차 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db030391-4c14-4b60-a594-05d8a89ed051",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'predicts' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmath\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m sqrt\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28msum\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m predict, actual \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[43mpredicts\u001b[49m, actual):\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28msum\u001b[39m \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (predict \u001b[38;5;241m-\u001b[39m actual) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[1;32m      8\u001b[0m sqrt(\u001b[38;5;28msum\u001b[39m \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(predicts))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'predicts' is not defined"
     ]
    }
   ],
   "source": [
    "from math import sqrt\n",
    "\n",
    "sum = 0\n",
    "\n",
    "for predict, actual in zip(predicts, actual):\n",
    "    sum += (predict - actual) ** 2\n",
    "    \n",
    "sqrt(sum / len(predicts))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a54ec4f7-ef58-48e9-8def-466002159b89",
   "metadata": {},
   "source": [
    "- 사이킷런에는 mean_squared_error 함수(평균제곱근오차가 아닌 평균제곱오차 함수임!)로 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36a7dfb5-4017-4efc-b19f-2687df514cc4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_actual' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mean_squared_error\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmath\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m sqrt\n\u001b[0;32m----> 4\u001b[0m rms \u001b[38;5;241m=\u001b[39m sqrt(mean_squared_error(\u001b[43my_actual\u001b[49m, y_predict))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'y_actual' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "\n",
    "rms = sqrt(mean_squared_error(y_actual, y_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a34c8f11-6b6b-42f2-8c22-326726f962f5",
   "metadata": {},
   "source": [
    "\n",
    "### 3.2.2 결정 계수<sup>coefficient determination</sup>\n",
    "\n",
    "- 회귀로 근사한 방정식을 평가하는 지표로 R<sup>2</sup>로 표현됨\n",
    "> $ 결정 계수(R^2) = 1 - \\frac{\\sum_i{(예측값_i - 실젯값_i)^2}}{\\sum_i{(예측값_i - 실젯값의 평균)^2}} $\n",
    "\n",
    "- 항상 평균을 출력하는 예측 모델보다 성능이 얼마나 더 좋은가를 표현\n",
    "- 1에 가까울수록 성능이 좋음\n",
    "- 사이킷런의 r2_score 함수를 사용하여 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "546a634a-d7da-4100-91bc-fd9904ecad0f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [6]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinear_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LinearRegression\n\u001b[1;32m      2\u001b[0m lr \u001b[38;5;241m=\u001b[39m LinearRegression()\n\u001b[0;32m----> 4\u001b[0m lr\u001b[38;5;241m.\u001b[39mfit(\u001b[43mx\u001b[49m, y)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m r2_score\n\u001b[1;32m      7\u001b[0m r2 \u001b[38;5;241m=\u001b[39m r2_score(y, lr\u001b[38;5;241m.\u001b[39mpredict(x))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'x' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "lr = LinearRegression()\n",
    "\n",
    "lr.fit(x, y)\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "r2 = r2_score(y, lr.predict(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16e99684-9f6b-4288-bec4-f2953d57b894",
   "metadata": {},
   "source": [
    "- 회귀 모델은 linearRegression의 score(x, y) 함수를 이용하여 결정 계수를 구할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f78faa-e38c-4140-b6d3-622aa6e14226",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90e1634f-60e5-4311-93e4-c9d9df5eceec",
   "metadata": {},
   "source": [
    "# 3.3 머신러닝 시스템의 A/B 테스트\n",
    "\n",
    "> A/B테스트  \n",
    "변수 A에 비해 대상이 변수 B에 대해 보이는 응답을 테스트하고, 두 변수 중 어떤 것이 더 효과적인지를 판단함으로써 단일 변수에 대한 두 가지 버전을 비교하는 방법\n",
    "\n",
    "- 온라인 서비스에서 모델을 적용하지 않았을 경우와 각각의 모델을 적용 했을 경우의 성과를 비교하는 방식으로 최적의 모델을 선택\n",
    "- 시스템을 A/B 테스트를 적용할 수 있는 형태로 구성할 경우 새로운 모델을 단계적으로 출시하거나 롤백하는 것이 가능하여 검증 주기를 빠르게 하거나 기회 비용을 줄일 수 있음\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87c9ba90-3fc2-4af5-9853-2f31bed3a32a",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32888cde-b453-47f4-924b-9182d253734d",
   "metadata": {},
   "source": [
    "# 3.4 정리\n",
    "\n",
    "- 분류 작업에서 사용되는 지표들\n",
    "    - 정밀도\n",
    "    - 정확도\n",
    "    - 재현율\n",
    "    - F-점수\n",
    "- 실무에서는 혼동행렬을 작성하여 성능을 파악하는 것이 중요\n",
    "- 회귀 작업용 평가 지표들\n",
    "    - 평균제곱근오차\n",
    "    - 결정 계수\n",
    "- 모델의 성능향상만을 좇지 말고 비지니스 관점에서의 KPI를 염두에 두어야 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d348b8-e358-4f1e-8dd8-cc70633354f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
