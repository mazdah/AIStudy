{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "746ceaa7-48b6-4eff-8652-a29f5410b3d8",
   "metadata": {},
   "source": [
    "# 7.1 효과 검증\n",
    "\n",
    "- 어떤 시책에 의해 발생한 효과를 추정하는 기법\n",
    "- 효과 검증을 통해 출시한 기능의 유효성을 판단하고 데이터 기반 의사결정을 할 수 있다.\n",
    "\n",
    "### 7.1.1 비즈니스 지표를 이용한 정책 평가\n",
    "\n",
    "- 에측 모델 자체가 아니라 의사결정 시스템에서의 단위 성능에 주목\n",
    "- 예측 정확도가 향상되면 무엇이 좋아지는지에 대한 설명이 필요\n",
    "\n",
    "### 7.1.2 정책을 실행한 후의 효과 검증의 중요성\n",
    "\n",
    "- 정책을 실행한 결과를 올바르게 검증하는 단계는 대부분의 경우에 필요하다.\n",
    "- 효과가 확실하지 않은 경우 손실이 발생할 수도 있다.\n",
    "\n",
    "### 7.1.3 오프라인 검증과 온라인 검증\n",
    "\n",
    "- 오프라인 검증: 과거 데이터를 사용해 시뮬레이션\n",
    "- 온라인 검증: 실제 제품에 머신러닝을 적용해 실험을 수행\n",
    "- 오프라인 검증으로 제품 구현 여부를 결정한 후 온라인 검증을 수행\n",
    "\n",
    "### 7.1.4 지표 선정\n",
    "\n",
    "- 제품의 장기적인 목표에 가까운 지표를 선택하는 것이 좋다.\n",
    "- **대체 지표**<sup>proxy metrics</sup>: 지표 대신 사용할 수 있는 지표\n",
    "    - 마일스톤이 되는 선행 지표 중 목표 지표와 비례 관걔가 있는 것으로 대체 지표를 설정하는 것이 좋다.\n",
    "- 중간 지표를 그대로 사용할 경우 후속 지표가 악화되지 않도록 주의해야 한다.\n",
    "- 검증은 지표를 측정할 수 있다는 것을 전제로 하므로 시스템 로그 출력 및 저장 정책 확인과 측정 방법이 없는 경우 측정 구조를 만드는 것이 필요하다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb2ff72-0b4b-42f5-b00b-63236f894913",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b359dadb-a9fe-4e18-aaac-d9c2396d921c",
   "metadata": {},
   "source": [
    "# 7.2 인과 효과 추정\n",
    "\n",
    "### 7.2.1 상관관계와 인과관계\n",
    "\n",
    "- 상관관계가 있다고 해서 반드시 인과관계가 있는 것은 아니다.\n",
    "- **혼재 인자**<sup>confounding factor</sup>: 두 인자에 영향을 주는 인자\n",
    "    - 효과 검증에서는 혼재 인자의 경향을 얼마나 제거하는지가 중요.\n",
    "    \n",
    "### 7.2.2 루빈의 인과관계 모델\n",
    "\n",
    "- 인터넷 광고를 예로 한 인과추론 용어\n",
    "    - **개입**<sup>cause</sup>: 광고를 보여주는 것\n",
    "    - **결과 변수**<sup>outcome</sup>: 구매 행동\n",
    "    - **실험군(개입군)**<sup>treatment group</sup>: 개입한 표본\n",
    "    - **대조군(통제군)**<sup>control group</sup>: 개입하지 않은 표본\n",
    "- 관측되지 않은 일에 대해 평가할 수 없음(광고에 접촉한 A가 동시에 광고에 접촉하지 않은 상태가 될 수는 없음)\n",
    "\n",
    "![한쪽 케이스만 확인](./images/rubin1.png)\n",
    "\n",
    "- **루빈 인과모형**<sup>Rubin Causal Model</sup>(RCM)은 관측은 불가능하지만 잠재적으로 존재할 수 있던 결과변수(**잠재적 결과변수**)를 고려할 수 있음.\n",
    "- **평균처리효과**<sup>average treatment effect</sup>(ATE): 각각의 표본이 개입했을 때의 결과와 개입하지 않았을 때의 결과이 차에 대한 기댓값\n",
    "\n",
    "![평균 처리 효과](./images/rubin1.png)\n",
    "\n",
    "> $ ATE = E(Y_1 - Y_0) = E(Y_1) - E(Y_0) $ [식 1]  \n",
    "> $Y_0$: 개입을 했을 때의 결과, $Y_1$: 개입하지 않은 경우의 결과\n",
    "\n",
    "### 7.2.3 선택 편향에 의한 위장 효과\n",
    "\n",
    "- 평균 처리 효과 계산: '개입군의 결과 변수의 평균' - '대조군의 결과 변수의 평균'\n",
    "    - $E(Y_1 | 개입합) - E(Y_0 | 개입하지 않음)$ [식 2]\n",
    "    \n",
    "- 개입 여부와 결과 변수에 상관관계가 있으면 [식 1]과 일치하지 않는다.\n",
    "- **선택 편향**<sup>selection bias</sup>: 개입과 결과 변수 사이에 상관관계를 만들어 **효과가 없음에도 효과가 있는 듯 보이느 데이터를 만드는 것**\n",
    "- 애초에 구매 행동으로 이어질 것 같은 사용자를 타겟으로 개입을 하게 되고 이로 인해 개입군과 대조군에 차이가 발생하며 이는 선택 편향으로 나타난다.\n",
    "- 올바른 결과 비교를 위해서는 편향을 제거해야 함\n",
    "\n",
    "### 7.2.4 무작위 비교 시험\n",
    "\n",
    "- 혼재 인자나 선택 편향에 의해 식 1과 식 2가 일치하는 않게 됨\n",
    "- **무작위 비교 시험**<sup>randomized control trial</sup>(RCT): 편향이 없는 상태를 만들어 비교하는 방법. 이런 경우 식 1과 식 2는 같아지게 된다.\n",
    "- RCT는 사회 실험이나 임상 시험에서는 비용이 높으나 웹 서비스 요과 검증에는 적용하기 쉬워 A/B 테스트의 기본이 됨\n",
    "\n",
    "### 7.2.5 과거와 비교한 판단\n",
    "\n",
    "- 새로운 조치를 시행했더라도 그 조치로 인해 이전 시기에 비해 변화가 발생했다고 판단하기는 어렵다(많은 외부 요인들 존재).\n",
    "- 시계열 데이터를 이용하기 보다는 RCT로 동일한 기간의 두 그룹을 비교하는 편이 더 간결하고 외부 요인을 통제하기 쉽다.\n",
    "- 캐주얼 임팩트<sup>causal impact</sup>라는 기법도 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a49236e8-19a6-4c20-b9ee-58302babb5aa",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f644970-a9a0-417b-bd55-0ebef534c485",
   "metadata": {},
   "source": [
    "# 7.3 가설 검정 프레임\n",
    "\n",
    "- 효과 검증의 기반\n",
    "- **가설 검정**<sup>hypothesis testing</sup>: A/B 테스트에 기반한 표본(샘플)을 사용해 모집단을 판단하는 기법.\n",
    "\n",
    "### 7.3.1 가설 검정이 필요한 이유\n",
    "\n",
    "- 편차가 없는 적은 수의 표본으로 모집단을 판단할 수 있음.\n",
    "\n",
    "### 7.3.2 동전이 찌그러지진 않았을까\n",
    "\n",
    "- **귀무가설**<sup>null hypothesis</sup>: 일반적으로 기각될 것이 예상되어 세워진 가설\n",
    "- **대립가설**<sup>alternative hypothesis</sup>: 검증을 통해 입증하고싶은 가설\n",
    "- **p-값**<sup>p-value</sup>: 귀무가설이 참일 때의 확률\n",
    "- **유의수준**<sup>significant level</sup>: 귀무가설이 참임에도 기각될 확률. 일반적으로 5%(0.05)\n",
    "- **표본 수와 표본 크기**: 표본을 구성하는 원소 수(예, 5명의 조사원이 1000 명씩의 대상을 조사하는 경우 표본 수는 5, 표본 크기는 1000)\n",
    "\n",
    "> 동전을 20번 던져 앞면이 15번, 뒷면이 5번 나온 경우  \n",
    "> * '앞면이 나올 확률은 50%다'는 귀무가설  \n",
    "> * '앞면이 나올 확률은 50%가 아니다'는 대립가설  \n",
    "> * 표본은 최근에 동전을 던진 기록  \n",
    "> * 표본 수는 1\n",
    "> * 표본 크기는 20(20번 던진 것)  \n",
    "> * 모집단은 해당 동전을 던진 모든 시행\n",
    "\n",
    "### 7.3.3 획득한 사용자의 지속 이용률 비교\n",
    "\n",
    "- **최소 검출 효과**<sup>minimum detectable effect</sup>(MDE): 검출하고자 하는 최소 효과량\n",
    "\n",
    "### 7.3.4 차이의 신뢰 구간 구하기\n",
    "\n",
    "- 효과 검증에서는 차이의 크기, 즉 요과량에 초점을 맞춘다.\n",
    "- p값만 사용하는 것보다 차이의 신뢰 추정값에서 많은 정보를 얻을 수 있다.\n",
    "\n",
    "### 7.3.5 거짓 양성과 거짓 음성\n",
    "\n",
    "- **거짓 양성**<sup>false positive</sup>(1종 오류<sup>Type 1 Error</sup>, 알파 오류<sup>$ \\alpha $ Error</sup>): 유의 수준에 의해 귀무가설이 참인데도 불구하고 기각하도록 판단하는 것\n",
    "- **거짓 음성**<sup>false negative</sup>(2종 오류<sup>Type 2 Error</sup>, 베타 오류<sup>$ \\beta $ Error</sup>): 귀무가설이 거짓임에도 기각하지 못한 경우\n",
    "- **검정력**<sup>power</sup>: 유의한 차이를 바르게 찾아내는 능력\n",
    "\n",
    "> 검정력 = 1 - (유의한 차이가 있는데 차이가 없다고 판정할 확률)\n",
    "\n",
    "- 작은 차이를 검출하는 데는 큰 표본의 크기가 필요하다.\n",
    "\n",
    "### 7.3.6 p값 조작\n",
    "\n",
    "- p값을 사용한 연구의 재현성이 낮음\n",
    "- p값 조작: 대표적으로 가설 검증을 잘못 사용하는 경우\n",
    "- 가설 검정에서는 대상의 표본을 고정시켜야 한다.\n",
    "- 검정을 반복하면 유의한 차이가 발생한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3108f701-0619-406e-a461-8564edfb0d3d",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c04e0d38-c2d3-4323-a02e-a8e70e808ee5",
   "metadata": {},
   "source": [
    "# 7.4 A/B 테스트 설계 및 수행\n",
    "\n",
    "- A/B 테스트는 두 조건을 기반으로 운영 환경에서 수행하는 테스트를 활용해 웹 서비스에서의 정책 효과 검정에 널리 사용된다.\n",
    "- 과정\n",
    "    - 지표 선정\n",
    "    - 두 그룹 선정\n",
    "    - A/A 테스트\n",
    "    - 한 그룹에 개입\n",
    "    - 결과 확인\n",
    "    - 테스트 종료\n",
    "    \n",
    "### 7.4.1 그룹 선정과 표본 크기\n",
    "\n",
    "- 표본의 크기에 따른 차이\n",
    "| 케이스 | 검증 방법 | 표본 크기 |\n",
    "|---|---|---|\n",
    "| A | 기존 사용자를 두 그룹으로 나누어 한쪽에만 개입한 뒤 1인당<br>매출 평균에 차이가 나는지 검증한다. | 두 그룹을 처음 만든 시점에서 고정된다. |\n",
    "| B | 사용자 신규 가입 등록 화면의 새 디자인과 기존 디자인을 비교해<br>등록 완료율에 차이가 있는지 검증한다. 신규 사용자가<br>방문하면 일정한 확률로 새 디자인을 보여준다. | 신규 사용자가 있는 한 계속 증가한다. |\n",
    "\n",
    "- 표본의 크기가 너무 작으면 적절한 결과가 나오지 않는 경우가 발생하고 너무 크면 테스트 대상이 되는 조치의 효과가 반감될 수 있다.\n",
    "- 사용자 모두를 두 그룹으로 나눠 테스트하면 다른 테스트를 동시에 수행할 수 없다.\n",
    "- 테스트한 실험군과 대조군을 재활용하면 이전 테스트의 영향을 받을 수 있어 좋지 않으므로 테스트마다 그룹을 추출해야 한다.\n",
    "\n",
    "### 지속적인 7.4.2 A/B 테스트 및 종료 판정\n",
    "\n",
    "- 온라인 테스트에서는 순차적으로 관측되는 데이터 때문에 표본의 크기가 점점 커진다. 이런 경우 임으의 시점에서 판단을 내리므로 **순처적 A/B 테스트딩**<sup>sequential A/B testing</sup>이라고 부르기도 한다.\n",
    "- 시간을 투자해 표본 크기를 늘릴수록 판단을 내리기 쉬워진다.\n",
    "- 새로운 관측 데이터를 순차적으로 얻는 테스트에서의 종료 시점은 명확하지 않다.\n",
    "- 모평균이 달라지는 테스트의 경우 평균의 추이를 신뢰구간과 겹쳐 보면서 종료 시점을 판단한다.\n",
    "- 표본의 크기가 클수록 판단은 쉽고, 테스트 결과를 빠르게 판단하는 것은 좋은 정책을 빠르게 적용할 수 있어 가치가 있다.\n",
    "- 반면 효과가 좋지 않은 정책은 테스트를 빨리 중단해야 한다.\n",
    "- A/B 테스트 시행 시 테스트 종료 시한을 정해두는 것이 좋다.\n",
    "\n",
    "### 7.4.3 A/A 테스트를 이용한 균질성 확인\n",
    "\n",
    "- A/A 테스트: 무작위 추출에 따라 품질이 같은 두 그룹을 얻었는지 확인하는 것.\n",
    "\n",
    "### 7.4.4 정책 상호 작용에 주의\n",
    "\n",
    "- 두 정책에 대해 동시에 테스트를 실시하여 결과를 비교하는 경우 서로에게 여향을 미치지 않도록 주의해야 한다.\n",
    "- 이를 위해 테스트 대상인 두 그룹 사이에 공유하는 요소는 없는지 테스트 설계 단계에서 확인해야 한다.\n",
    "\n",
    "### 7.4.5 A/B 테스트 프레임 구축\n",
    "\n",
    "- 머신러닝 적용 시 예측 모듈이 학습 데이터에 영향을 주고 있다면 학습 데이터를 분리해야 한다.\n",
    "\n",
    "![오염된 로그](./images/pollutedlog.png)\n",
    "\n",
    "- 마이크로소프트 A/B 테스트팀의 활용 방법\n",
    "    - 효과가 좋지 않은 테스트를 조기 중단하는 알림 및 자동 정지\n",
    "    - 테스트 간의 상호작용을 자동으로 검출"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00fe95ef-51bf-4817-ba2f-ef9d6698c06c",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d945df-8b39-4c59-bc4d-67594cad2b9a",
   "metadata": {},
   "source": [
    "# 7.5 오프라인 검증\n",
    "\n",
    "- 제품 코드를 작성하기 전 실험으로 할 수 있는 오프라인 평가 실험\n",
    "\n",
    "### 7.5.1 비지니스 지표를 사용한 예측 모델 평가\n",
    "\n",
    "![예측이 맞았을 때와 맞지 않았을 때 일어나는 일](./images/result.png)\n",
    "\n",
    "### 7.5.2 반사실 다루기\n",
    "\n",
    "- 반사실: 관측하지 못한 사실\n",
    "- 분명하지 않은 결과를 다룰 때 가장 편한 방법은 가능한 역량을 예측하고 이를 이용한 결과를 만들어 평가하는 것이다. 단, 평가 결과의 신뢰도는 가능한 역량 예측 정확도에 좌우된다.\n",
    "\n",
    "### 7.5.3 Off Policy Evaluation\n",
    "\n",
    "- 효과 검증에서의 중요한 점은 **예측으로 어떤 행동을 하는 시스템 관점에서의 성능**\n",
    "- **Off Policy Evaluation(OPE)**: 과거의 다른 정책에 따라 생성한 로그에 기반해 행동 결정 정책을 평가하는 것\n",
    "- 불연속적인 행동에 적용할 수 있는 정책 성능 평가 기법"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b514719e-bc5e-41af-90e0-e82667526495",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d667cd15-9d96-4a2d-ba5d-88b606f570df",
   "metadata": {},
   "source": [
    "# 7.6 A/B 테스트를 수행할 수 없을 경우\n",
    "\n",
    "- 관찰 데이터: 무작위로 비교한 실험에서 얻어낸 실험 데이터로 자연스럽게 얻어지는 결과\n",
    "\n",
    "### 7.6.1 관찰 데이터를 사용한 효과 검증\n",
    "\n",
    "- 대조군을 얻을 수 없어 혼재 인자의 영향이나 선택 편향을 제거하기 어려움\n",
    "- **차이의 차이 기법**<sup>defference in difference</sup>: 실험군과 유사한 경향을 나타내는 그룹의 결과 변수의 시간 변화를 활용해 개입 전후를 비교하는 기법\n",
    "- 그밖에 설명 모델을 이용한 중회귀 분석 방법, 개입 확률을 이용해 편향을 보정하는 방법, 비교 대조 시계열을 만드는 방법 등이 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36da1e28-f647-475d-ad07-1e9e69968874",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b50965f-edc5-43ef-96d3-fa8bb3380bd1",
   "metadata": {},
   "source": [
    "# 7.7 정리\n",
    "\n",
    "- 효과 검증에만 국한된 것이 아니라 편향에 주의해 데이터를 다루는 것은 데이터에서 가치를 얻는 업무에서 매우 중요한 자세다.\n",
    "- 요약\n",
    "    - 루빈의 인과관계 모델에 기반한 인과 효과 추정은 올바른 비교에 도움이 된다.\n",
    "    - 오프라인 검증은 비용이 드는 A/B 테스트를 줄이면서 개발 주기를 빠르게 할 수 있다.\n",
    "    - 웹 서비스의 온라인 검증은 낮은 비용으로 많은 표본을 얻을 수 있다.\n",
    "- 효과 검증 결과는 비지니스에도 공유되어야 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "623abde5-fdae-4a82-a8b4-9f8944e197bf",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0c3a6b6-b049-4658-8a75-f86017d282aa",
   "metadata": {},
   "source": [
    "# 7.8 쉬어가가: 무조건 성공하는 A/B 테스트, A/B 테스트 모집단 조작\n",
    "\n",
    "- A/B 테스트 수행 목적\n",
    "    - 여러 정책 중 더 나은 정책을 선택한다.\n",
    "    - 새로운 정책을 실시할 때 좋지 않은 결과가 나타나면 즉시 중지한다.\n",
    "- 무조건 성공하는 A/B 테스트를 설계할 수 있다는 맹점이 있다.\n",
    "\n",
    "### 7.8.1 모집단 통제를 통한 A/B 테스트 조작\n",
    "\n",
    "- **대부분이 0이고 음의 값을 갖지 않는 KPI**를 **A/B 테스트의 평가 지표로 삼는 경우** 무조건 성공하는 A/B 테스트가 된다.\n",
    "- 매출이나 전환율 등은 음의 값을 가질 수 없는 지표이다.\n",
    "\n",
    "### 7.8.2 휴면 고객에게 접근\n",
    "\n",
    "- 효과가 없는 정책을 효과가 있는 정책과 조합하여 효과가 있게 보이도록 하는 경우도 있다.\n",
    "\n",
    "### 7.8.3 뒤로가기 버튼 조작\n",
    "\n",
    "- 뒤로가기 버튼을 누른 고객에게 그대로 나갈 것인지 몯는 경고창으로 붙잡는 확실하게 성공하는 A/B 테스트 설계가 가능\n",
    "\n",
    "### 7.8.4 모집단 조작 찾기\n",
    "\n",
    "- 모집단 조작을 찾아내기 위해서는 **적절한 베이스라인 정책이 설정되었는지 확인**한다.\n",
    "- A/B 테스트 정책 비교시 조작 여부 확인 방법\n",
    "    - 모집단이 항상 0이 세그먼트를 이용하지 않았는가?\n",
    "    - 여러 정책이 하나의 그룹 안에 섞여 있지 않은가?\n",
    "    - 베이스라인 정책이 올바르게 설계되어 있는가?\n",
    "    \n",
    "### 7.8.5 휴면 고객을 활용한 낮은 리스크의 실험을 통해 성공 사례 축적\n",
    "\n",
    "- 휴면 고객에 대한 접근 방식은 머신러닝 시스템 도입에서 매우 효과적인 방식임"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b93c76f3-5cad-4089-a4da-9832fb7a3ba2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
